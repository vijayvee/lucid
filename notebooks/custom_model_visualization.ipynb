{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom model visualization\n",
    "\n",
    "#### This notebook is a walkthrough to use TensorFlow's amazing visualization tool, Lucid, on your custom built TensorFlow CNN models. \n",
    "\n",
    "#### Please star if you like my notebook, thanks :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all modules for lucid visualization\n",
    "\n",
    "from lucid.modelzoo.vision_base import Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import lucid.optvis.render as render\n",
    "import lucid.optvis.objectives as objectives\n",
    "import lucid.optvis.param as param\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class for your custom model by inheriting \n",
    "# lucid's Model superclass..\n",
    "# Mention input_name with scoping..\n",
    "\n",
    "class EID_Resnet_6reg(Model):\n",
    "    model_path = '/media/data_cifs/clicktionary/clickme_experiment/nsf_correlation_models/6_reg/frozen_model.pb.modelzoo'\n",
    "    image_shape = [224,224,3]\n",
    "    image_value_range = (0,1)\n",
    "    input_name = 'cnn/rgb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where the real deal happens. \n",
    "\n",
    "eid = EID_Resnet_6reg()\n",
    "eid.load_graphdef()\n",
    "\n",
    "\n",
    "# Following is an example on creating parameters to visualize a custom layer, say, Conv35 of the model I loaded above.\n",
    "channel = lambda n: objectives.channel('cnn/conv2d_35/Conv2D', n)\n",
    "\n",
    "# Creates example objective functions for the first 5 neurons in Conv2d_35\n",
    "objs = [channel(i) for i in range(5)]\n",
    "param_f = lambda: param.image(224)\n",
    "\n",
    "# You shall be able to create visualizations for the first 5 neurons in Conv2d_35 using the above objectives \n",
    "# and parameters.\n",
    "\n",
    "# Let us now look at the tutorial to visualize ALL conv layers in a ConvNet using the above model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all objectives you created for different neurons\n",
    "def makedir(path):\n",
    "    if not os.path.exists(path):\n",
    "        mkdir(path)\n",
    "        \n",
    "master_output_path = './Lucid-Visualizations'\n",
    "makedir(master_output_path)\n",
    "\n",
    "# Feel free to substitute 'Conv2D' with any kind of layer you'd like to visualize\n",
    "all_convs = [node.name for node in eid.graph_def.node if 'Conv2D' in node.name]\n",
    "\n",
    "for layer in all_convs:\n",
    "    print 'Rendering visualizations for layer %s'%(layer)\n",
    "    \n",
    "    # Create directories to store rendered visualizations\n",
    "    \n",
    "    curr_conv_layer = '_'.join(layer.split('/'))\n",
    "    layer_output_path = os.path.join(master_output_path,\n",
    "                                        curr_conv_layer)\n",
    "    makedir(layer_output_path)\n",
    "    \n",
    "    # Create objective functions for the current layer (sample code for first 5 neurons)\n",
    "    channel = lambda n: objectives.channel(layer, n)\n",
    "    objs = [channel(i) for i in range(10)]\n",
    "    \n",
    "    # Main loop for rendering visualizations\n",
    "    for ind_obj, obj in enumerate(objs):\n",
    "        print 'Rendering visualizations for neuron-%s'%(ind_obj)\n",
    "        \n",
    "        # Store/display rendered visualizations \n",
    "        # upto 1000 iterations, at 200 step intervals\n",
    "        \n",
    "        imgs = render.render_vis(eid, obj, param_f, thresholds=np.arange(0,10000,1000))\n",
    "        curr_layer_fn = 'Visualized_Rendering_%s_%s.npy'%(ind_obj,\n",
    "                                                          curr_conv_layer)\n",
    "        curr_layer_path = os.path.join(layer_output_path, curr_layer_fn)\n",
    "        np.save(curr_layer_path, imgs)\n",
    "        print 'Saved in %s'%(curr_layer_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
